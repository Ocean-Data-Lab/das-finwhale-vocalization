{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "pio.renderers.default = 'colab'\n",
    "root_dir = '/home/hunteryt/notebooks/Capstone_Project/south_dist_chunked_10000to47495_dx5_fs100_bpf14to35Hz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83935ba6",
   "metadata": {},
   "source": [
    "## Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import in clustering results\n",
    "df = pd.read_csv('../data/eighty_cluster_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa878339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get approximate likelihood of \n",
    "def get_confidence_proportion(conf_level):\n",
    "    \"\"\"\n",
    "    Based on Confidence level return approximate confidence proportion\n",
    "    \"\"\"\n",
    "    if conf_level == 3:\n",
    "        return 1\n",
    "    elif conf_level == 2:\n",
    "        return 0.67\n",
    "    elif conf_level == 1:\n",
    "        return 0.33\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['confidence_proportion'] = df.signal_confidence.apply(get_confidence_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images of data\n",
    "class DASImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=transforms.ToTensor()):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = os.listdir(self.root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file =(os.path.join(self.root_dir, self.files[index]))\n",
    "        img = Image.open(img_file)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.files[index]\n",
    "    \n",
    "orig_transform = transforms.Compose([transforms.ToTensor()])\n",
    "orig_images = DASImageDataset(root_dir=root_dir, transform=orig_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12480c81",
   "metadata": {},
   "source": [
    "## Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_plotly(df):\n",
    "    return {'z': df.confidence_proportion.tolist(),\n",
    "            'x': df.time_start.str.replace(' ', 'T').tolist(),\n",
    "            'y': df.distance_start.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b327ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Heatmap(df_to_plotly(df)))\n",
    "fig.update_layout(\n",
    "    title='Fin Whale Vocalizations Heatmap',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Distance from shore (m)',\n",
    "    legend_title='Confidence Level',\n",
    "    hovermode='closest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
